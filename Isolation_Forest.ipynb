{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program runs the Isolation Forest method over the KDDCUP99 dataset to determine if data instances within the set are normal or anomalous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.datasets import fetch_kddcup99\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kddcup99_data = fetch_kddcup99(subset='http')\n",
    "X = kddcup99_data['data']\n",
    "y = kddcup99_data['target']\n",
    "y[y == b'normal.'] = 1\n",
    "y[y!= 1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1  1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1 -1 -1  1  1  1 -1  1 -1  1\n",
      " -1  1 -1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1\n",
      " -1 -1  1  1]\n"
     ]
    }
   ],
   "source": [
    "isof = IsolationForest(max_samples=100, random_state=42)\n",
    "isof.fit(X)\n",
    "anomaly_predictions = isof.predict(X)\n",
    "print(anomaly_predictions[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_sweep(n):\n",
    "    isof = IsolationForest(max_samples=n, random_state=42)\n",
    "    isof.fit(X)\n",
    "    anomaly_predictions = isof.predict(X)\n",
    "\n",
    "    \n",
    "    import pandas as pd\n",
    "    df_confusion = pd.crosstab(y, anomaly_predictions)\n",
    "    TP = df_confusion.iloc[0,0]  # True Positives\n",
    "    FP = df_confusion.iloc[0,1]  # False Positives\n",
    "    FN = df_confusion.iloc[1,0]  # False Negatives\n",
    "    TN = df_confusion.iloc[1,1]  # True Negatives\n",
    "\n",
    "    precision_score = TP/(TP+FP)\n",
    "    recall_score = TP/(TP+FN)\n",
    "    f1_score = 2*((precision_score*recall_score)/(precision_score+recall_score))\n",
    "\n",
    "    true_positive_rate = TP/(TP + FN)\n",
    "    false_positive_rate = FP/(FP+TN)\n",
    "    \n",
    "    print('\\nPrecision Score = ', precision_score)\n",
    "    print('\\nRecall Score = ', recall_score)\n",
    "    print('\\nF1 Score = ', f1_score)\n",
    "    print('\\nTrue Positive Rate = ', true_positive_rate)\n",
    "    print('\\nFalse Positive Rate = ', false_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision Score =  0.001358080579447714\n",
      "\n",
      "Recall Score =  0.017857142857142856\n",
      "\n",
      "F1 Score =  0.0025241901556583932\n",
      "\n",
      "True Positive Rate =  0.017857142857142856\n",
      "\n",
      "False Positive Rate =  0.037672694980958724\n"
     ]
    }
   ],
   "source": [
    "param_sweep(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the max_samples parameter set so low, the algorithm performed extremely poorly, detecting almost no anamolies and incorrectly labeling others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision Score =  0.996831145314622\n",
      "\n",
      "Recall Score =  0.1656884875846501\n",
      "\n",
      "F1 Score =  0.28414736434608684\n",
      "\n",
      "True Positive Rate =  0.1656884875846501\n",
      "\n",
      "False Positive Rate =  0.00015406624848684935\n"
     ]
    }
   ],
   "source": [
    "param_sweep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By increasing this parameter by 1, the precision increased significantly and was able to correctly identify anomalies. However, the algorithm did not even get close to detecting all anomalies present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision Score =  1.0\n",
      "\n",
      "Recall Score =  0.16815102382583544\n",
      "\n",
      "F1 Score =  0.28789261045223513\n",
      "\n",
      "True Positive Rate =  0.16815102382583544\n",
      "\n",
      "False Positive Rate =  0.0\n"
     ]
    }
   ],
   "source": [
    "param_sweep(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By further increasing the max samples the algorithm was able to detect only anomalies, though many anomalies were still missed. We will continue to increase this parameter to determine what the optimal value for max samples is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision Score =  1.0\n",
      "\n",
      "Recall Score =  0.21542812560951824\n",
      "\n",
      "F1 Score =  0.3544892882933483\n",
      "\n",
      "True Positive Rate =  0.21542812560951824\n",
      "\n",
      "False Positive Rate =  0.0\n"
     ]
    }
   ],
   "source": [
    "param_sweep(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision Score =  1.0\n",
      "\n",
      "Recall Score =  0.24720232766338407\n",
      "\n",
      "F1 Score =  0.39641094661283083\n",
      "\n",
      "True Positive Rate =  0.24720232766338407\n",
      "\n",
      "False Positive Rate =  0.0\n"
     ]
    }
   ],
   "source": [
    "param_sweep(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision Score =  1.0\n",
      "\n",
      "Recall Score =  0.33188100961538464\n",
      "\n",
      "F1 Score =  0.4983643542019177\n",
      "\n",
      "True Positive Rate =  0.33188100961538464\n",
      "\n",
      "False Positive Rate =  0.0\n"
     ]
    }
   ],
   "source": [
    "param_sweep(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision Score =  1.0\n",
      "\n",
      "Recall Score =  0.45772896808951513\n",
      "\n",
      "F1 Score =  0.6280028429282161\n",
      "\n",
      "True Positive Rate =  0.45772896808951513\n",
      "\n",
      "False Positive Rate =  0.0\n"
     ]
    }
   ],
   "source": [
    "param_sweep(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision Score =  1.0\n",
      "\n",
      "Recall Score =  0.444466800804829\n",
      "\n",
      "F1 Score =  0.6154060454102243\n",
      "\n",
      "True Positive Rate =  0.444466800804829\n",
      "\n",
      "False Positive Rate =  0.0\n"
     ]
    }
   ],
   "source": [
    "param_sweep(1250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision Score =  1.0\n",
      "\n",
      "Recall Score =  0.4931904442956017\n",
      "\n",
      "F1 Score =  0.6605861244019139\n",
      "\n",
      "True Positive Rate =  0.4931904442956017\n",
      "\n",
      "False Positive Rate =  0.0\n"
     ]
    }
   ],
   "source": [
    "param_sweep(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision Score =  1.0\n",
      "\n",
      "Recall Score =  0.5081665516448125\n",
      "\n",
      "F1 Score =  0.6738865161683953\n",
      "\n",
      "True Positive Rate =  0.5081665516448125\n",
      "\n",
      "False Positive Rate =  0.0\n"
     ]
    }
   ],
   "source": [
    "param_sweep(1700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision Score =  1.0\n",
      "\n",
      "Recall Score =  0.5189100305379375\n",
      "\n",
      "F1 Score =  0.6832663161150634\n",
      "\n",
      "True Positive Rate =  0.5189100305379375\n",
      "\n",
      "False Positive Rate =  0.0\n"
     ]
    }
   ],
   "source": [
    "param_sweep(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision Score =  0.05341783612494341\n",
      "\n",
      "Recall Score =  0.058823529411764705\n",
      "\n",
      "F1 Score =  0.05599051008303677\n",
      "\n",
      "True Positive Rate =  0.058823529411764705\n",
      "\n",
      "False Positive Rate =  0.036865953207919744\n"
     ]
    }
   ],
   "source": [
    "param_sweep(2400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
